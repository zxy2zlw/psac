import torch
import torch.nn as nn
import os
from torch.utils.data import DataLoader
import numpy as np
import pandas as pd
from Model import Deepnet
import gc
import seaborn as sns
import matplotlib.pyplot as plt
from torch.utils.data import random_split
from index import cofusion_matrix, sensitivity, specificity, auc, mcc, accuracy, precision, recall, f1, cutoff, AUPRC
metrics_dict = {"sensitivity":sensitivity, "specificity":specificity, "accuracy":accuracy,"mcc":mcc,"auc":auc,"precision":precision,"recall":recall,"f1":f1,"AUPRC":AUPRC}

def encode(DNA_sequence):
    torch_sq = []
    encode_ = {'A' : 0, 'C' : 1 , 'G' : 2 , 'T' : 3 }
    for base in DNA_sequence:
        base = encode_[base]
        torch_sq.append(base)
    x = torch.tensor(torch_sq)
    x = x.flatten()
    return x

def dataProcessing(path):
    file = open(path, "r")
    l1 = len(open(path).readlines())
    count = 0
    Training = [0] * l1
    for line in file:
        Data = line.strip('\n')
        Training[count] = encode(Data)
        count = count + 1
    return Training

def prepareData(PositiveCSV, NegativeCSV):
    Positive = dataProcessing(PositiveCSV)
    Negative = dataProcessing(NegativeCSV)
    
    len_data1 = len(Positive)
    len_data2 = len(Negative)
    
    Positive_y = torch.ones(len_data1, dtype=torch.float32)  
    Negative_y = torch.zeros(len_data2, dtype=torch.float32)
    
    for num in range(len(Positive)):
        Positive[num] = tuple((Positive[num],Positive_y[num]))
        Negative[num] = tuple((Negative[num],Negative_y[num]))
    Dataset = Positive + Negative
    return Dataset

def Modeltraining(PositiveCSV, NegativeCSV,bs,net,lr,epoches,PATH, modelname):
    """
    Trains a deep neural network model.

    Args:
    - PositiveCSV: Path to the file containing positive samples.
    - NegativeCSV: Path to the file containing negative samples.
    - bs: Batch size.
    - net: Deep neural network model.
    - lr: Learning rate.
    - epoches: Number of epochs.
    - PATH: Path to save the model.
    - modelname: Name of the model.

    """
    AllData = prepareData(PositiveCSV,NegativeCSV)
    train_dataset, test_dataset = random_split(dataset=AllData,lengths=[0.8,0.2],generator=torch.Generator())
    
    traindata = DataLoader(train_dataset,batch_size=bs,shuffle=True,drop_last=True,pin_memory=True)
    testdata = DataLoader(test_dataset,batch_size=bs,shuffle=True,drop_last=True,pin_memory=True)
    
    criterion = nn.BCELoss()
    opt = torch.optim.Adadelta(net.parameters(),lr=lr,rho=0.9)
    highestAcc = None
    
    for epoch in range(epoches):
        train_pre, val_pre, train_labels, val_labels = [], [], [], []
        
        net = net.mps()
        net.train()
        for num,(x,y) in enumerate(traindata):
            x = x.mps()
            y = y.mps()
            opt.zero_grad(set_to_none=True)
            yhat,_ = net.forward(x)
            yhat = yhat.flatten()
            loss = criterion(yhat,y)
            loss.backward()
            nn.utils.clip_grad_norm_(net.parameters(), 3, norm_type=2)
            opt.step()
            train_pre.extend(yhat.cpu().clone().detach().numpy().flatten().tolist())
            train_labels.extend(y.cpu().clone().detach().numpy().astype('int32').flatten().tolist()) 
        
        print("================================================", flush = True)
        print(f"epoch = {epoch+1}")
        for key in metrics_dict.keys():
                if(key != "auc" and key != "AUPRC"):
                    metrics = metrics_dict[key](train_labels, train_pre, thresh = 0.5)
                else:
                    metrics = metrics_dict[key](train_labels, train_pre)
                print("train_" + key + ": " + str(metrics), flush=True) 
                
        tn_t, fp_t, fn_t, tp_t = cofusion_matrix(train_labels, train_pre, thresh = 0.5)
        print("train_true_negative:: value: %f, epoch: %d" % (tn_t, epoch + 1), flush=True)
        print("train_false_positive:: value: %f, epoch: %d" % (fp_t, epoch + 1), flush=True)
        print("train_false_negative:: value: %f, epoch: %d" % (fn_t, epoch + 1), flush=True)
        print("train_true_positive:: value: %f, epoch: %d" % (tp_t, epoch + 1), flush=True)
        
        del x,y,yhat,tn_t, fp_t, fn_t, tp_t,train_labels,train_pre,metrics
        gc.collect()
        torch.mps.empty_cache()
        
        print("------------------------------------------------", flush = True)
        
        selist = []
        net.eval()
        net = net.mps()
        for num, (x, y) in enumerate(testdata):
            with torch.no_grad():
                x =  torch.LongTensor(x)
                x = x.mps()
                y = y.mps()
                yhat,se = net(x)
                
                yhat = yhat.flatten()
                loss = criterion(yhat,y)
                val_pre.extend(yhat.cpu().detach().numpy().flatten().tolist())
                val_labels.extend(y.cpu().detach().numpy().astype('int32').flatten().tolist())
        loss_epoch = criterion(torch.tensor(val_pre).float(), torch.tensor(val_labels).float())
        
        print("validation loss:: "+ str(loss_epoch), flush = True)
        for key in metrics_dict.keys():
                if(key != "auc" and key != "AUPRC"):
                    metrics = metrics_dict[key](val_labels, val_pre, thresh = 0.5)
                    
                    if(key == "f1"):
                        if (highestAcc == None) or (highestAcc < metrics):
                            highestAcc = metrics
                            torch.save(net.state_dict(), os.path.join(PATH, modelname + ".pt"))
                            print("Weights Saved")
                
                else:
                    metrics = metrics_dict[key](val_labels, val_pre)
                print("validation_" + key + ": " + str(metrics), flush=True)
                
        tn_t, fp_t, fn_t, tp_t = cofusion_matrix(val_labels, val_pre, thresh = 0.5)
        print("validation_true_negative:: value: %f, epoch: %d" % (tn_t, epoch + 1), flush=True)
        print("validation_false_positive:: value: %f, epoch: %d" % (fp_t, epoch + 1), flush=True)
        print("validation_false_negative:: value: %f, epoch: %d" % (fn_t, epoch + 1), flush=True)
        print("validation_true_positive:: value: %f, epoch: %d" % (tp_t, epoch + 1), flush=True)
        del x,y,yhat,tn_t, fp_t, fn_t, tp_t,val_labels,val_pre,metrics
        attention_weights = se.cpu().numpy()  # 转为 NumPy 数组
        fig, ax = plt.subplots(figsize=(12,4)) 
        sns.heatmap(attention_weights, cmap="YlGnBu", annot=False, fmt=".2f", xticklabels=False, yticklabels=False)
        plt.title('R.chinensis position Weights')
        ax.set_xticks(np.arange(attention_weights.shape[1]) + 0.5, minor=False)
        ax.set_xticklabels(np.arange(1, attention_weights.shape[1] + 1))
        plt.xlabel('Sequence Positions')
        plt.savefig(f'object\code\imgr/heatmap_{epoch}.png')
        plt.close()  # 关闭当前的图形，以便下次循环重新创建
        gc.collect()
        torch.mps.empty_cache()
    
torch.manual_seed(520)
torch.mps.manual_seed(520)
PositivePath = "object/6mA/6mA_R.chinensis\pos_test.txt"
NegativePath = "object/6mA/6mA_R.chinensis/neg_test.txt"
net = Deepnet(feature=128,dropout=0.3,filter_num=128,seq_len=41).to("mps",non_blocking=True)
Path = "object\code"
modelname = "DNA_model_test"

# net.load_state_dict (torch.load('object\code\DNA_model_A.thaliana.pt'))
Modeltraining(PositiveCSV=PositivePath, NegativeCSV=NegativePath,bs=256,net = net,lr=1.0,epoches=100,PATH=Path, modelname=modelname)
print("finish!")
